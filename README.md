# neural-inference-optimizer
High-performance Transformer inference suite implementing KV-caching and PyTorch graph compilation to reduce decoding complexity from O(N^2) to O(N)
